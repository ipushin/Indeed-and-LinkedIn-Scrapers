{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import cfscrape\n",
    "from lxml import etree\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating list of companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting up-to-date list of companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df2gspread import gspread2df as g2d\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "spreadsheet_key = '1YrmtRylZG9z6fBc3pp-WEnaA2v5s-Z0yqVWWrgpEod8'\n",
    "scope = ['https://spreadsheets.google.com/feeds'] \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/macbook/Downloads/gs-credentials.json', scope) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_comps = g2d.download(gfile=spreadsheet_key, wks_name = 'UPD Companies', credentials=credentials, col_names=True, row_names=True)\n",
    "upd_comps = upd_comps.reset_index(drop=True).rename(columns={'Company Name':'Company Original'})\n",
    "upd_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list_comps = pd.read_csv('Indeed_Companies-09-08-2020.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking companies that are in the up-to-date list but out of the current list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comps = [x for x in upd_comps['Company Original'].unique() if x not in current_list_comps['Company Original'].unique()]\n",
    "len(new_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many new companies\n",
    "upd_comps.shape[0] - current_list_comps.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking companies that were processed but not included in up-to-date list of companies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Real Page', 'Aspen Technology']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in current_list_comps['Company Original'].unique() if x not in upd_comps['Company Original'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comps_df = pd.DataFrame(new_comps, columns=['Company Original'])\n",
    "new_comps_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining new companies to the list of companies\n",
    "companies_list = pd.concat([current_list_comps, new_comps_df], ignore_index=True)\n",
    "companies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/macbook/Downloads/Chrome Driver/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://www.indeed.com/companies?from=gnav-homepage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting companies pages on Indeed \n",
    "+ Pay attention to the search results on Indeed. It needs to be checked manually since Indeed can show wrong companies in search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "206 Scale.ai | Scale.ai https://www.indeed.com/cmp/Scale.ai\n",
      "207\n",
      "207 Postman | ＰＯＳＴＭＡＮ https://www.indeed.com/cmp/%EF%BC%B0%EF%BD%8F%EF%BD%93%EF%BD%94%EF%BD%8D%EF%BD%81%EF%BD%8E\n",
      "208\n",
      "208 Nylas | nylas https://www.indeed.com/cmp/Nylas\n",
      "209\n",
      "209 Checkr  | Checkr https://www.indeed.com/cmp/Checkr\n",
      "210\n",
      "210 Auth0 | Auth0 https://www.indeed.com/cmp/Auth0\n",
      "211\n",
      "211 Segment | Segment https://www.indeed.com/cmp/Segment\n",
      "212\n",
      "212 Cloudinary | Cloudinary https://www.indeed.com/cmp/Cloudinary\n",
      "213\n",
      "213 Infobip  | Cloudinary https://www.indeed.com/cmp/Cloudinary\n",
      "214\n",
      "214 MessageBird  | Cloudinary https://www.indeed.com/cmp/Cloudinary\n",
      "215\n",
      "215 SendBird | SendBird https://www.indeed.com/cmp/Sendbird\n",
      "216\n",
      "216 Agora.io  | Agora.io https://www.indeed.com/cmp/Agora.io\n",
      "217\n",
      "217 Marqeta | Marqeta https://www.indeed.com/cmp/Marqeta\n",
      "218\n",
      "218 Algolia | Algolia https://www.indeed.com/cmp/Algolia\n",
      "219\n",
      "219 Sift | SIFT https://www.indeed.com/cmp/Sift\n",
      "220\n",
      "220 Firebase | Firebase https://www.indeed.com/cmp/Firebase\n",
      "221\n",
      "221 Nexmo | Nexmo https://www.indeed.com/cmp/Nexmo\n",
      "222\n",
      "222 Checkout | checkout food stores https://www.indeed.com/cmp/Checkout-Food-Stores-1\n",
      "223\n",
      "223 Plaid | Plaid https://www.indeed.com/cmp/Plaid\n",
      "224\n",
      "224 Rapyd | Rapyd https://www.indeed.com/cmp/Rapyd\n",
      "225\n",
      "225 TuSimple | TuSimple https://www.indeed.com/cmp/Tusimple\n",
      "226\n",
      "226 Cardlytics | Cardlytics https://www.indeed.com/cmp/Cardlytics\n",
      "227\n",
      "227 Mercury.co | Mercury https://www.indeed.com/cmp/Mercury\n",
      "CPU times: user 2.46 s, sys: 216 ms, total: 2.67 s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in companies_list.iloc[-len(new_comps):].index:\n",
    "    try:\n",
    "        company = companies_list['Company Original'].loc[i]\n",
    "        sleep(2)\n",
    "        search_input = '/html/body/div[1]/div/div[1]/div/div/form/div[1]/div/div/div/div[2]/input'\n",
    "        browser.find_element_by_xpath(search_input).send_keys(company)\n",
    "        sleep(0.5)\n",
    "        browser.find_element_by_xpath(search_input).send_keys(Keys.ENTER)\n",
    "        sleep(0.5)\n",
    "        browser.find_element_by_xpath(search_input).send_keys(Keys.ENTER)\n",
    "        sleep(3)\n",
    "\n",
    "        path = '//*[@class=\"cmp-CompanyWidget-name\"]'\n",
    "        url = browser.find_element_by_xpath(path).get_attribute('href')\n",
    "        indeed_name = browser.find_element_by_xpath(path).text\n",
    "\n",
    "        companies_list['Indeed Name'].loc[i] = indeed_name\n",
    "        companies_list['Indeed URL'].loc[i] = url\n",
    "        companies_list['Home Page Jobs'].loc[i] = companies_list['Indeed URL'].loc[i] + '/jobs'\n",
    "        print(i, company, '|', indeed_name, url)\n",
    "        sleep(1)\n",
    "        for _ in range(30):\n",
    "            browser.find_element_by_xpath(search_input).send_keys(Keys.BACK_SPACE)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    sleep(1)\n",
    "    for _ in range(30):\n",
    "        browser.find_element_by_xpath(search_input).send_keys(Keys.BACK_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#companies_list.iloc[-len(new_comps):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#companies_list.to_csv('Indeed_Companies-{}.csv'.format(date.today().strftime(\"%d-%m-%Y\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting companies metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cfscrape.create_scraper()\n",
    "scraper = cfscrape.create_scraper(sess=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 207 | Postman | San Francisco https://www.indeed.com/cmp/%EF%BC%B0%EF%BD%8F%EF%BD%93%EF%BD%94%EF%BD%8D%EF%BD%81%EF%BD%8E\n",
      "# 208 | Nylas | San Francisco https://www.indeed.com/cmp/Nylas\n",
      "# 209 | Checkr  | San Francisco https://www.indeed.com/cmp/Checkr\n",
      "# 210 | Auth0 | Bellevue https://www.indeed.com/cmp/Auth0\n",
      "# 211 | Segment | The Greenway Iconic Offices Block C, Ardilaun Court 112-114 St. Stephen's Green Dublin 2, D02 TD28 https://www.indeed.com/cmp/Segment\n",
      "# 212 | Cloudinary | Santa Clara https://www.indeed.com/cmp/Cloudinary\n",
      "# 213 | Infobip  | London https://www.indeed.com/cmp/Infobip\n",
      "# 214 | MessageBird  | Amsterdam https://www.indeed.com/cmp/Messagebird\n",
      "# 215 | SendBird | San Mateo https://www.indeed.com/cmp/Sendbird\n",
      "# 216 | Agora.io  | Santa Clara https://www.indeed.com/cmp/Agora.io\n",
      "# 217 | Marqeta | Oakland https://www.indeed.com/cmp/Marqeta\n",
      "# 218 | Algolia | San Francisco https://www.indeed.com/cmp/Algolia\n",
      "# 219 | Sift | San Francisco https://www.indeed.com/cmp/Sift\n",
      "# 220 | Firebase | San Francisco https://www.indeed.com/cmp/Firebase\n",
      "# 222 | Checkout | Checkout.com, Wenlock Works, 41 Shepherdess Walk, Hoxton, London N1 7QE, UK https://www.indeed.com/cmp/Checkout.com\n",
      "# 224 | Rapyd | London https://www.indeed.com/cmp/Rapyd\n",
      "# 225 | TuSimple | San Diego https://www.indeed.com/cmp/Tusimple\n",
      "# 226 | Cardlytics | nan https://www.indeed.com/cmp/Cardlytics\n"
     ]
    }
   ],
   "source": [
    "for i in companies_list.iloc[-len(new_comps):].index:\n",
    "    sleep(1)\n",
    "    link = companies_list['Indeed URL'].loc[i]\n",
    "    try:\n",
    "        browser.get(link)\n",
    "        path = '//*[@class=\"cmp-AboutMetadata\"]' \n",
    "        meta_raw = browser.find_element_by_xpath(path).text\n",
    "        \n",
    "        companies_list['Comp Metadata'].loc[i] = meta_raw\n",
    "        \n",
    "        meta = meta_raw.split('\\n')        \n",
    "        for n,j in enumerate(meta):\n",
    "            if meta[n-1] == 'Headquarters':\n",
    "                companies_list['Headquarters'].loc[i] = j\n",
    "                break\n",
    "        \n",
    "        print('#', i, '|', companies_list['Company Original'].loc[i], '|', companies_list['Headquarters'].loc[i], link)\n",
    "    \n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list['Headquarters'].loc[210] = 'Bellevue, Washington'\n",
    "companies_list['Headquarters'].loc[215] = 'Broadwick St, Soho, London W1F 0DB, United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list.to_csv('Indeed_Companies-{}.csv'.format(date.today().strftime(\"%d-%m-%Y\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "import googlemaps\n",
    "\n",
    "api_key = 'AIzaSyDRTtALAU8Tjb3711Z4dho7WZp7Ygcpk6g'\n",
    "gmaps = googlemaps.Client(key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 54 ms, total: 193 ms\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx in companies_list.iloc[-len(new_comps):].index:\n",
    "    sleep(1)\n",
    "\n",
    "    addr = companies_list['Headquarters'].loc[idx]\n",
    "    google_addr = gmaps.geocode(addr)\n",
    "    companies_list['GoogleMap Metadata'].loc[idx] = google_addr\n",
    "    \n",
    "    companies_list['Headquarters Address'].loc[idx] = companies_list['GoogleMap Metadata'].loc[idx][0]['formatted_address']\n",
    "    companies_list['Headquarters Country'].loc[idx] = companies_list['Headquarters Address'].loc[idx].split(', ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#companies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Regional Indeed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "reional_pages_posts = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 7 Atlassian num_jobs 26\n",
      "Pulled Jobs 26 \n",
      "\n",
      "# 20 Dassault Systemes num_jobs 34\n",
      "Pulled Jobs 34 \n",
      "\n",
      "# 32 Fortnox NO JOBS \n",
      "\n",
      "# 37 Jira NO JOBS \n",
      "\n",
      "# 66 Xero num_jobs 86\n",
      "Pulled Jobs 86 \n",
      "\n",
      "# 106 Shopify num_jobs 1\n",
      "Pulled Jobs 1 \n",
      "\n",
      "# 110 Adidas num_jobs 102\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 112 Farfetch NO JOBS \n",
      "\n",
      "# 114 Shift Technology num_jobs 5\n",
      "Pulled Jobs 5 \n",
      "\n",
      "# 116 Adyen num_jobs 40\n",
      "Pulled Jobs 40 \n",
      "\n",
      "# 125 World Pay NO JOBS \n",
      "\n",
      "# 127 Klarna num_jobs 65\n",
      "Pulled Jobs 65 \n",
      "\n",
      "# 128 Afterpay NO JOBS \n",
      "\n",
      "# 129 Asos num_jobs 49\n",
      "Pulled Jobs 49 \n",
      "\n",
      "# 130 Boohoo num_jobs 82\n",
      "Pulled Jobs 82 \n",
      "\n",
      "# 132 Zalando num_jobs 399\n",
      "Pulled Jobs 299 \n",
      "\n",
      "# 133 Zooplus NO JOBS \n",
      "\n",
      "# 141 N26 NO JOBS \n",
      "\n",
      "# 142 Revolut NO JOBS \n",
      "\n",
      "# 143 Monzo num_jobs 15\n",
      "Pulled Jobs 15 \n",
      "\n",
      "# 149 Takeaway.com num_jobs 110\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 150 Just Eat num_jobs 185\n",
      "Pulled Jobs 185 \n",
      "\n",
      "# 152 Deliveroo num_jobs 38\n",
      "Pulled Jobs 38 \n",
      "\n",
      "# 161 Valve num_jobs 4\n",
      "Pulled Jobs 4 \n",
      "\n",
      "# 172 Canonical num_jobs 18\n",
      "Pulled Jobs 18 \n",
      "\n",
      "# 184 JetBrains num_jobs 13\n",
      "Pulled Jobs 13 \n",
      "\n",
      "# 192 MySQL AB NO JOBS \n",
      "\n",
      "# 195 Odoo num_jobs 10\n",
      "Pulled Jobs 10 \n",
      "\n",
      "# 203 SUSE num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 211 Segment num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 213 Infobip  num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 214 MessageBird  num_jobs 14\n",
      "Pulled Jobs 14 \n",
      "\n",
      "# 215 SendBird num_jobs 4\n",
      "Pulled Jobs 4 \n",
      "\n",
      "# 222 Checkout NO JOBS \n",
      "\n",
      "# 224 Rapyd NO JOBS \n",
      "\n",
      "CPU times: user 16.3 s, sys: 1.17 s, total: 17.5 s\n",
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_job_on_regional_pages = []\n",
    "for i in companies_list[companies_list['Headquarters Country']!='USA'].index:\n",
    "    \n",
    "    try:\n",
    "        company = companies_list['Company Original'].loc[i]\n",
    "        url = companies_list['Regional Indeed Jobs'].loc[i]\n",
    "        browser.get(url)\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        path = '//*[@class=\"cmp-JobListJobCount-jobCount\"]' \n",
    "        num_jobs = browser.find_element_by_xpath(path).text\n",
    "        num_jobs = re.sub(r'[^\\.\\,\\d]', '', num_jobs[:10])\n",
    "        num_jobs = re.sub(r'\\,| |\\.','', num_jobs)\n",
    "        num_jobs = int(num_jobs)\n",
    "    \n",
    "    except:\n",
    "        print('#', i, company, 'NO JOBS', '\\n')\n",
    "        no_job_on_regional_pages.append(company)\n",
    "        continue\n",
    "    \n",
    "    page_data = pd.DataFrame({'Company':company,\n",
    "                              'Raw Data':np.nan,\n",
    "                              'Job Title':np.nan,\n",
    "                              'Job Number':num_jobs,\n",
    "                              'Posting Date':np.nan,\n",
    "                              'Job Place':np.nan,}, index = range(num_jobs))\n",
    "    \n",
    "    print('#', i, company, 'num_jobs', num_jobs)\n",
    "    \n",
    "    for i in range(1,101):\n",
    "        try:\n",
    "            # Raw Data\n",
    "            div = 3\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(div, i)\n",
    "            raw = browser.find_element_by_xpath(path).text\n",
    "            page_data['Raw Data'].loc[i-1] = raw\n",
    "        \n",
    "        except:\n",
    "            try:\n",
    "                # Raw Data\n",
    "                div = 2\n",
    "                path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(div, i)\n",
    "                raw = browser.find_element_by_xpath(path).text\n",
    "                page_data['Raw Data'].loc[i-1] = raw\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            # Job Title\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(div, i)\n",
    "            title = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Title'].loc[i-1] = title\n",
    "            \n",
    "            # Date\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(div, i)\n",
    "            date_post = browser.find_element_by_xpath(path).text\n",
    "            if 'easily' in date_post.lower():\n",
    "                path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(div, i)\n",
    "                date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "            page_data['Posting Date'].loc[i-1] = date_post\n",
    "\n",
    "            # Place\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(div, i)\n",
    "            place = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Place'].loc[i-1] = place\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if num_jobs>100:\n",
    "        for n in range(1, num_jobs//150+1):\n",
    "            try:\n",
    "                link = url + '?start={}'.format(150*n)\n",
    "                browser.get(link)\n",
    "                sleep(2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for i in range(1,101):\n",
    "                try:\n",
    "                    \n",
    "                    # Raw Data\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(div, i)\n",
    "                    raw = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Raw Data'].loc[n*100+i-1] = raw\n",
    "                    \n",
    "                    # Job Title\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(div, i)\n",
    "                    title = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Title'].loc[n*100+i-1] = title\n",
    "\n",
    "                    # Date\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(div, i)\n",
    "                    date_post = browser.find_element_by_xpath(path).text\n",
    "                    if 'easily' in date_post.lower():\n",
    "                        path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(div, i)\n",
    "                        date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "                    page_data['Posting Date'].loc[n*100+i-1] = date_post\n",
    "\n",
    "                    # Place\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[{}]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(div, i)\n",
    "                    place = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Place'].loc[n*100+i-1] = place\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    page_data = page_data[((~page_data['Raw Data'].isna())) |\n",
    "                          ((~page_data['Job Title'].isna()) &\n",
    "                          (~page_data['Posting Date'].isna()) &\n",
    "                          (~page_data['Job Place'].isna()))].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    print('Pulled Jobs', page_data.shape[0],'\\n')\n",
    "    \n",
    "    reional_pages_posts = pd.concat([reional_pages_posts, page_data], axis=0, ignore_index=True)\n",
    "    reional_pages_posts['Current Date'] = date.today().strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_job_on_regional_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293, 7)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reional_pages_posts = reional_pages_posts.drop_duplicates()\n",
    "reional_pages_posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Job Postings from Companies pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages_posts = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 8X8 num_jobs 14\n",
      "Pulled Jobs 14 \n",
      "\n",
      "# 1 Adobe num_jobs 103\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 2 ADP num_jobs 406\n",
      "Pulled Jobs 300 \n",
      "\n",
      "# 3 Akamai num_jobs 39\n",
      "Pulled Jobs 39 \n",
      "\n",
      "# 4 Alteryx num_jobs 25\n",
      "Pulled Jobs 25 \n",
      "\n",
      "# 5 Anaplan NO JOBS\n",
      "# 6 Ansys num_jobs 172\n",
      "Pulled Jobs 172 \n",
      "\n",
      "# 7 Atlassian num_jobs 65\n",
      "Pulled Jobs 65 \n",
      "\n",
      "# 8 Autodesk num_jobs 214\n",
      "Pulled Jobs 164 \n",
      "\n",
      "# 9 Bill.com num_jobs 31\n",
      "Pulled Jobs 31 \n",
      "\n",
      "# 10 Cadence Design num_jobs 103\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 11 Ceridian num_jobs 603\n",
      "Pulled Jobs 403 \n",
      "\n",
      "# 12 Check Point Software NO JOBS\n",
      "# 13 Citirix num_jobs 127\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 14 Cloudera num_jobs 18\n",
      "Pulled Jobs 18 \n",
      "\n",
      "# 15 Cloudflare num_jobs 83\n",
      "Pulled Jobs 83 \n",
      "\n",
      "# 16 Cornerstone on Demand num_jobs 15\n",
      "Pulled Jobs 15 \n",
      "\n",
      "# 17 Coupa num_jobs 56\n",
      "Pulled Jobs 56 \n",
      "\n",
      "# 18 CyberArk num_jobs 29\n",
      "Pulled Jobs 29 \n",
      "\n",
      "# 19 Datadog num_jobs 140\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 20 Dassault Systemes num_jobs 11\n",
      "Pulled Jobs 11 \n",
      "\n",
      "# 21 Docusign num_jobs 161\n",
      "Pulled Jobs 161 \n",
      "\n",
      "# 22 Domo num_jobs 21\n",
      "Pulled Jobs 21 \n",
      "\n",
      "# 23 Dropbox num_jobs 41\n",
      "Pulled Jobs 41 \n",
      "\n",
      "# 24 Dynatrace num_jobs 15\n",
      "Pulled Jobs 15 \n",
      "\n",
      "# 25 Everbridge num_jobs 24\n",
      "Pulled Jobs 24 \n",
      "\n",
      "# 26 Fastly num_jobs 30\n",
      "Pulled Jobs 30 \n",
      "\n",
      "# 27 FireEye num_jobs 127\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 28 Five9 num_jobs 58\n",
      "Pulled Jobs 58 \n",
      "\n",
      "# 29 ForeScout num_jobs 19\n",
      "Pulled Jobs 19 \n",
      "\n",
      "# 30 Fortinet num_jobs 172\n",
      "Pulled Jobs 172 \n",
      "\n",
      "# 31 Fortive num_jobs 6\n",
      "Pulled Jobs 6 \n",
      "\n",
      "# 32 Fortnox NO JOBS\n",
      "# 33 Guidewire num_jobs 59\n",
      "Pulled Jobs 59 \n",
      "\n",
      "# 34 Heroku NO JOBS\n",
      "# 35 Hubspot num_jobs 53\n",
      "Pulled Jobs 53 \n",
      "\n",
      "# 36 Intuit num_jobs 8788\n",
      "Pulled Jobs 5900 \n",
      "\n",
      "# 37 Jira NO JOBS\n",
      "# 38 Juniper num_jobs 54\n",
      "Pulled Jobs 54 \n",
      "\n",
      "# 39 Manhattan Associates num_jobs 31\n",
      "Pulled Jobs 31 \n",
      "\n",
      "# 40 Medallia num_jobs 46\n",
      "Pulled Jobs 46 \n",
      "\n",
      "# 41 MongoDB num_jobs 82\n",
      "Pulled Jobs 82 \n",
      "\n",
      "# 42 NetApp num_jobs 102\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 43 Okta num_jobs 122\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 44 Palantir num_jobs 62\n",
      "Pulled Jobs 62 \n",
      "\n",
      "# 45 Palo Alto Networks num_jobs 230\n",
      "Pulled Jobs 180 \n",
      "\n",
      "# 46 Pardot NO JOBS\n",
      "# 47 Paycom num_jobs 200\n",
      "Pulled Jobs 200 \n",
      "\n",
      "# 48 Ping Identity num_jobs 53\n",
      "Pulled Jobs 53 \n",
      "\n",
      "# 49 PTC num_jobs 87\n",
      "Pulled Jobs 87 \n",
      "\n",
      "# 50 Qualtrics num_jobs 61\n",
      "Pulled Jobs 61 \n",
      "\n",
      "# 51 Qualys num_jobs 44\n",
      "Pulled Jobs 44 \n",
      "\n",
      "# 52 Rapid7 num_jobs 51\n",
      "Pulled Jobs 51 \n",
      "\n",
      "# 53 ServiceNow num_jobs 324\n",
      "Pulled Jobs 224 \n",
      "\n",
      "# 54 Sinch num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 55 Slack num_jobs 103\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 56 Smartsheet num_jobs 51\n",
      "Pulled Jobs 51 \n",
      "\n",
      "# 57 Splunk num_jobs 719\n",
      "Pulled Jobs 500 \n",
      "\n",
      "# 58 Synopsys num_jobs 112\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 59 Tenable num_jobs 26\n",
      "Pulled Jobs 26 \n",
      "\n",
      "# 60 Twilio num_jobs 173\n",
      "Pulled Jobs 173 \n",
      "\n",
      "# 61 UiPath NO JOBS\n",
      "# 62 Ultimate Software num_jobs 82\n",
      "Pulled Jobs 82 \n",
      "\n",
      "# 63 Veeva System num_jobs 481\n",
      "Pulled Jobs 400 \n",
      "\n",
      "# 64 VMWare num_jobs 948\n",
      "Pulled Jobs 648 \n",
      "\n",
      "# 65 Workday num_jobs 118\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 66 Xero num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 67 Zendesk num_jobs 50\n",
      "Pulled Jobs 50 \n",
      "\n",
      "# 68 Zoom num_jobs 98\n",
      "Pulled Jobs 98 \n",
      "\n",
      "# 69 Zscaler num_jobs 137\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 70 Ringcentral num_jobs 140\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 71 Snowflake NO JOBS\n",
      "# 72 Elastic num_jobs 30\n",
      "Pulled Jobs 30 \n",
      "\n",
      "# 73 Box num_jobs 79\n",
      "Pulled Jobs 79 \n",
      "\n",
      "# 74 Paylocity num_jobs 46\n",
      "Pulled Jobs 46 \n",
      "\n",
      "# 75 Procore num_jobs 50\n",
      "Pulled Jobs 50 \n",
      "\n",
      "# 76 Pluralsights num_jobs 18\n",
      "Pulled Jobs 18 \n",
      "\n",
      "# 77 Talend num_jobs 36\n",
      "Pulled Jobs 36 \n",
      "\n",
      "# 78 New Relic num_jobs 177\n",
      "Pulled Jobs 177 \n",
      "\n",
      "# 79 Varonis num_jobs 31\n",
      "Pulled Jobs 31 \n",
      "\n",
      "# 80 Real Page num_jobs 84\n",
      "Pulled Jobs 84 \n",
      "\n",
      "# 81 Aspen Technology num_jobs 52\n",
      "Pulled Jobs 52 \n",
      "\n",
      "# 82 Zillow num_jobs 155\n",
      "Pulled Jobs 155 \n",
      "\n",
      "# 83 Opendoor num_jobs 43\n",
      "Pulled Jobs 43 \n",
      "\n",
      "# 84 Offerpad num_jobs 32\n",
      "Pulled Jobs 32 \n",
      "\n",
      "# 86 Redfin num_jobs 573\n",
      "Pulled Jobs 400 \n",
      "\n",
      "# 87 Streeteasy NO JOBS\n",
      "# 88 Homelight num_jobs 26\n",
      "Pulled Jobs 26 \n",
      "\n",
      "# 89 Compass num_jobs 227\n",
      "Pulled Jobs 177 \n",
      "\n",
      "# 90 Tesla num_jobs 2451\n",
      "Pulled Jobs 1700 \n",
      "\n",
      "# 91 Rivian Automotive num_jobs 8\n",
      "Pulled Jobs 8 \n",
      "\n",
      "# 92 Wolfspeed NO JOBS\n",
      "# 93 Cree num_jobs 116\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 94 DraftKings num_jobs 44\n",
      "Pulled Jobs 44 \n",
      "\n",
      "# 95 FanDuel num_jobs 79\n",
      "Pulled Jobs 79 \n",
      "\n",
      "# 96 Fanatics num_jobs 71\n",
      "Pulled Jobs 71 \n",
      "\n",
      "# 97 StitchFix num_jobs 35\n",
      "Pulled Jobs 35 \n",
      "\n",
      "# 98 Revolve num_jobs 1\n",
      "Pulled Jobs 1 \n",
      "\n",
      "# 99 RealReal num_jobs 158\n",
      "Pulled Jobs 158 \n",
      "\n",
      "# 100 Chewy num_jobs 535\n",
      "Pulled Jobs 386 \n",
      "\n",
      "# 101 Wayfair num_jobs 447\n",
      "Pulled Jobs 300 \n",
      "\n",
      "# 102 Carvana num_jobs 431\n",
      "Pulled Jobs 300 \n",
      "\n",
      "# 103 Carmax num_jobs 1999\n",
      "Pulled Jobs 1400 \n",
      "\n",
      "# 104 Vroom num_jobs 64\n",
      "Pulled Jobs 64 \n",
      "\n",
      "# 105 Shift num_jobs 111\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 106 Shopify NO JOBS\n",
      "# 107 BigCommerce num_jobs 41\n",
      "Pulled Jobs 41 \n",
      "\n",
      "# 108 CommerceHub num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 109 Nike num_jobs 355\n",
      "Pulled Jobs 255 \n",
      "\n",
      "# 110 Adidas num_jobs 353\n",
      "Pulled Jobs 200 \n",
      "\n",
      "# 111 UnderArmour NO JOBS\n",
      "# 112 Farfetch NO JOBS\n",
      "# 113 Braintree NO JOBS\n",
      "# 114 Shift Technology num_jobs 3\n",
      "Pulled Jobs 3 \n",
      "\n",
      "# 115 Wix NO JOBS\n",
      "# 116 Adyen num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 117 Paypal num_jobs 708\n",
      "Pulled Jobs 500 \n",
      "\n",
      "# 118 Stripe NO JOBS\n",
      "# 119 FIS Global num_jobs 798\n",
      "Pulled Jobs 600 \n",
      "\n",
      "# 120 Fiserv num_jobs 618\n",
      "Pulled Jobs 418 \n",
      "\n",
      "# 121 Fleetcor num_jobs 70\n",
      "Pulled Jobs 70 \n",
      "\n",
      "# 122 Global Payments num_jobs 75\n",
      "Pulled Jobs 75 \n",
      "\n",
      "# 123 Mastercard num_jobs 280\n",
      "Pulled Jobs 200 \n",
      "\n",
      "# 124 Visa num_jobs 89\n",
      "Pulled Jobs 89 \n",
      "\n",
      "# 125 World Pay NO JOBS\n",
      "# 126 Affirm num_jobs 46\n",
      "Pulled Jobs 46 \n",
      "\n",
      "# 127 Klarna num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 128 Afterpay NO JOBS\n",
      "# 129 Asos NO JOBS\n",
      "# 130 Boohoo NO JOBS\n",
      "# 131 Etsy num_jobs 92\n",
      "Pulled Jobs 92 \n",
      "\n",
      "# 132 Zalando NO JOBS\n",
      "# 133 Zooplus NO JOBS\n",
      "# 134 Home Depot num_jobs 24100\n",
      "Pulled Jobs 15900 \n",
      "\n",
      "# 135 Lowes num_jobs 18867\n",
      "Pulled Jobs 12500 \n",
      "\n",
      "# 136 William Sonoma  num_jobs 326\n",
      "Pulled Jobs 226 \n",
      "\n",
      "# 137 Restoration Hardware num_jobs 515\n",
      "Pulled Jobs 365 \n",
      "\n",
      "# 138 Roku num_jobs 77\n",
      "Pulled Jobs 77 \n",
      "\n",
      "# 139 The Trade Desk NO JOBS\n",
      "# 140 Snap num_jobs 114\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 141 N26 num_jobs 5\n",
      "Pulled Jobs 5 \n",
      "\n",
      "# 142 Revolut num_jobs 19\n",
      "Pulled Jobs 19 \n",
      "\n",
      "# 143 Monzo NO JOBS\n",
      "# 144 Doordash num_jobs 14800\n",
      "Pulled Jobs 9800 \n",
      "\n",
      "# 145 Instacart num_jobs 105\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 146 Uber NO JOBS\n",
      "# 147 Lyft num_jobs 1286\n",
      "Pulled Jobs 900 \n",
      "\n",
      "# 148 Bolt num_jobs 34\n",
      "Pulled Jobs 34 \n",
      "\n",
      "# 149 Takeaway.com NO JOBS\n",
      "# 150 Just Eat NO JOBS\n",
      "# 151 Grubhub num_jobs 2182\n",
      "Pulled Jobs 1500 \n",
      "\n",
      "# 152 Deliveroo NO JOBS\n",
      "# 153 Discord num_jobs 60\n",
      "Pulled Jobs 60 \n",
      "\n",
      "# 154 Twitch num_jobs 68\n",
      "Pulled Jobs 68 \n",
      "\n",
      "# 155 100Thieves num_jobs 50\n",
      "Pulled Jobs 50 \n",
      "\n",
      "# 156 Square num_jobs 142\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 157 Zapier num_jobs 5\n",
      "Pulled Jobs 5 \n",
      "\n",
      "# 158 Tray.io num_jobs 1\n",
      "Pulled Jobs 1 \n",
      "\n",
      "# 159 Figma NO JOBS\n",
      "# 160 Chime num_jobs 1\n",
      "Pulled Jobs 1 \n",
      "\n",
      "# 161 Valve NO JOBS\n",
      "# 162 Coursera num_jobs 26\n",
      "Pulled Jobs 26 \n",
      "\n",
      "# 163 MasterClass num_jobs 17\n",
      "Pulled Jobs 17 \n",
      "\n",
      "# 164 Udemy NO JOBS\n",
      "# 165 Udacity num_jobs 20\n",
      "Pulled Jobs 20 \n",
      "\n",
      "# 166 Lambda School NO JOBS\n",
      "# 167 Codecademy num_jobs 42\n",
      "Pulled Jobs 42 \n",
      "\n",
      "# 168 Acquia num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 169 Aras num_jobs 15\n",
      "Pulled Jobs 15 \n",
      "\n",
      "# 170 Alfresco NO JOBS\n",
      "# 171 Automattic NO JOBS\n",
      "# 172 Canonical num_jobs 22\n",
      "Pulled Jobs 22 \n",
      "\n",
      "# 174 Confluent num_jobs 73\n",
      "Pulled Jobs 73 \n",
      "\n",
      "# 175 Couchbase num_jobs 30\n",
      "Pulled Jobs 30 \n",
      "\n",
      "# 176 Docker num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 177 Databricks num_jobs 88\n",
      "Pulled Jobs 88 \n",
      "\n",
      "# 178 Datastax num_jobs 5\n",
      "Pulled Jobs 5 \n",
      "\n",
      "# 179 ForgeRock num_jobs 44\n",
      "Pulled Jobs 44 \n",
      "\n",
      "# 180 GitHub NO JOBS\n",
      "# 181 GitLab NO JOBS\n",
      "# 182 HashiCorp num_jobs 32\n",
      "Pulled Jobs 32 \n",
      "\n",
      "# 183 Instructure num_jobs 16\n",
      "Pulled Jobs 16 \n",
      "\n",
      "# 184 JetBrains num_jobs 3\n",
      "Pulled Jobs 3 \n",
      "\n",
      "# 185 JFrog num_jobs 16\n",
      "Pulled Jobs 16 \n",
      "\n",
      "# 186 Kaltura num_jobs 6\n",
      "Pulled Jobs 6 \n",
      "\n",
      "# 187 Liferay NO JOBS\n",
      "# 188 Magento Commerce NO JOBS\n",
      "# 189 Mapbox NO JOBS\n",
      "# 190 Mozilla Corp NO JOBS\n",
      "# 191 MuleSoft NO JOBS\n",
      "# 192 MySQL AB NO JOBS\n",
      "# 193 Neo4j num_jobs 25\n",
      "Pulled Jobs 25 \n",
      "\n",
      "# 194 Nicira NO JOBS\n",
      "# 195 Odoo num_jobs 17\n",
      "Pulled Jobs 17 \n",
      "\n",
      "# 196 Pentaho NO JOBS\n",
      "# 197 Pivotal num_jobs 47\n",
      "Pulled Jobs 47 \n",
      "\n",
      "# 198 Puppet Labs NO JOBS\n",
      "# 199 RedHat num_jobs 140\n",
      "Pulled Jobs 100 \n",
      "\n",
      "# 200 Linden Lab num_jobs 3\n",
      "Pulled Jobs 3 \n",
      "\n",
      "# 201 Sourcefire NO JOBS\n",
      "# 202 SugarCRM num_jobs 33\n",
      "Pulled Jobs 33 \n",
      "\n",
      "# 203 SUSE num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 205 WP Engine num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 206 Scale.ai NO JOBS\n",
      "# 207 Postman NO JOBS\n",
      "# 208 Nylas NO JOBS\n",
      "# 209 Checkr  NO JOBS\n",
      "# 210 Auth0 num_jobs 72\n",
      "Pulled Jobs 72 \n",
      "\n",
      "# 211 Segment num_jobs 43\n",
      "Pulled Jobs 43 \n",
      "\n",
      "# 212 Cloudinary num_jobs 16\n",
      "Pulled Jobs 16 \n",
      "\n",
      "# 213 Infobip  num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 214 MessageBird  num_jobs 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled Jobs 7 \n",
      "\n",
      "# 215 SendBird num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "# 216 Agora.io  NO JOBS\n",
      "# 217 Marqeta num_jobs 31\n",
      "Pulled Jobs 31 \n",
      "\n",
      "# 218 Algolia num_jobs 17\n",
      "Pulled Jobs 17 \n",
      "\n",
      "# 219 Sift num_jobs 11\n",
      "Pulled Jobs 11 \n",
      "\n",
      "# 220 Firebase NO JOBS\n",
      "# 221 Nexmo NO JOBS\n",
      "# 222 Checkout num_jobs 7\n",
      "Pulled Jobs 7 \n",
      "\n",
      "# 224 Rapyd NO JOBS\n",
      "# 225 TuSimple num_jobs 402\n",
      "Pulled Jobs 300 \n",
      "\n",
      "# 226 Cardlytics num_jobs 9\n",
      "Pulled Jobs 9 \n",
      "\n",
      "CPU times: user 9min 41s, sys: 38.3 s, total: 10min 20s\n",
      "Wall time: 2h 59min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_job_on_pages = []\n",
    "for i in range(companies_list.shape[0]):\n",
    "    \n",
    "    try:\n",
    "        company = companies_list['Company Original'].loc[i]\n",
    "        url = companies_list['Home Page Jobs'].loc[i]\n",
    "        browser.get(url)\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        path = '//*[@class=\"cmp-JobListJobCount-jobCount\"]' \n",
    "        num_jobs = browser.find_element_by_xpath(path).text\n",
    "        num_jobs = re.findall(r'^.+(?= job)', num_jobs)[0]\n",
    "        num_jobs = re.sub(r'\\,| ','', num_jobs)\n",
    "        num_jobs = int(num_jobs)\n",
    "    \n",
    "    except:\n",
    "        print('#',i, company, 'NO JOBS')\n",
    "        no_job_on_pages.append(company)\n",
    "        continue\n",
    "    \n",
    "    page_data = pd.DataFrame({'Company':company,\n",
    "                              'Raw Data':np.nan,\n",
    "                              'Job Title':np.nan,\n",
    "                              'Job Number':num_jobs,\n",
    "                              'Posting Date':np.nan,\n",
    "                              'Job Place':np.nan,}, index = range(num_jobs))\n",
    "    \n",
    "    print('#', i, company, 'num_jobs', num_jobs)\n",
    "    \n",
    "    for i in range(1,101):\n",
    "        try:\n",
    "            # Raw Data\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(i)\n",
    "            raw = browser.find_element_by_xpath(path).text\n",
    "            page_data['Raw Data'].loc[i-1] = raw\n",
    "\n",
    "            # Job Title\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(i)\n",
    "            title = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Title'].loc[i-1] = title\n",
    "\n",
    "            # Date\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(i)\n",
    "            date_post = browser.find_element_by_xpath(path).text\n",
    "            if 'easily' in date_post.lower():\n",
    "                path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(i)\n",
    "                date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "            page_data['Posting Date'].loc[i-1] = date_post\n",
    "\n",
    "            # Place\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(i)\n",
    "            place = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Place'].loc[i-1] = place\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if num_jobs>100:\n",
    "        for n in range(1, num_jobs//150+1):\n",
    "            try:\n",
    "                link = url + '?start={}'.format(150*n)\n",
    "                browser.get(link)\n",
    "                sleep(2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for i in range(1,101):\n",
    "                try:\n",
    "                    \n",
    "                    # Raw Data\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(i)\n",
    "                    raw = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Raw Data'].loc[n*100+i-1] = raw\n",
    "\n",
    "                    # Job Title\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(i)\n",
    "                    title = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Title'].loc[n*100+i-1] = title\n",
    "\n",
    "                    # Date\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(i)\n",
    "                    date_post = browser.find_element_by_xpath(path).text\n",
    "                    if 'easily' in date_post.lower():\n",
    "                        path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(i)\n",
    "                        date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "                    page_data['Posting Date'].loc[n*100+i-1] = date_post\n",
    "\n",
    "                    # Place\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(i)\n",
    "                    place = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Place'].loc[n*100+i-1] = place\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    page_data = page_data[((~page_data['Raw Data'].isna())) |\n",
    "                          ((~page_data['Job Title'].isna()) &\n",
    "                          (~page_data['Posting Date'].isna()) &\n",
    "                          (~page_data['Job Place'].isna()))].reset_index(drop=True)\n",
    "\n",
    "    print('Pulled Jobs', page_data.shape[0], '\\n')\n",
    "    \n",
    "    pages_posts = pd.concat([pages_posts, page_data], axis=0, ignore_index=True)\n",
    "    pages_posts['Current Date'] = date.today().strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64708, 7)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_posts.to_csv('Indeed_Pages_Postings-{}.csv'.format(date.today().strftime(\"%d-%m-%Y\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missed companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66668, 7)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_df = pd.concat([pages_posts, reional_pages_posts], ignore_index=True)\n",
    "indeed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_comps = [x for x in current_list_comps['Company Original'].unique() if x not in indeed_df['Company'].unique()]\n",
    "len(missed_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 Anaplan NO JOBS\n",
      "# 1 Check Point Software NO JOBS\n",
      "# 2 Fortnox NO JOBS\n",
      "# 3 Heroku NO JOBS\n",
      "# 4 Jira NO JOBS\n",
      "# 5 Pardot NO JOBS\n",
      "# 6 UiPath NO JOBS\n",
      "# 7 Snowflake NO JOBS\n",
      "# 9 Streeteasy NO JOBS\n",
      "# 10 Wolfspeed NO JOBS\n",
      "# 11 Farfetch NO JOBS\n",
      "# 12 Stripe NO JOBS\n",
      "# 13 World Pay NO JOBS\n",
      "# 14 Afterpay NO JOBS\n",
      "# 15 Zooplus NO JOBS\n",
      "# 16 The Trade Desk NO JOBS\n",
      "# 17 Uber NO JOBS\n",
      "# 18 Figma NO JOBS\n",
      "# 19 Udemy NO JOBS\n",
      "# 20 Lambda School NO JOBS\n",
      "# 21 Alfresco NO JOBS\n",
      "# 22 Automattic NO JOBS\n",
      "# 24 GitHub NO JOBS\n",
      "# 25 GitLab NO JOBS\n",
      "# 26 Liferay NO JOBS\n",
      "# 27 Magento Commerce NO JOBS\n",
      "# 28 Mapbox NO JOBS\n",
      "# 29 Mozilla Corp NO JOBS\n",
      "# 30 MuleSoft NO JOBS\n",
      "# 31 MySQL AB NO JOBS\n",
      "# 32 Nicira NO JOBS\n",
      "# 33 Pentaho NO JOBS\n",
      "# 34 Puppet Labs NO JOBS\n",
      "# 35 Sourcefire NO JOBS\n",
      "# 37 Scale.ai NO JOBS\n",
      "# 38 Postman NO JOBS\n",
      "# 39 Nylas NO JOBS\n",
      "# 40 Checkr  NO JOBS\n",
      "# 41 Agora.io  NO JOBS\n",
      "# 42 Firebase NO JOBS\n",
      "# 43 Nexmo NO JOBS\n",
      "# 45 Rapyd NO JOBS\n",
      "CPU times: user 180 ms, sys: 28.9 ms, total: 209 ms\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, company in enumerate(missed_comps):\n",
    "    \n",
    "    try:\n",
    "        #company = companies_list['Company Original'].loc[i]\n",
    "        url = companies_list[companies_list['Company Original'] == company]['Home Page Jobs'].values[0]\n",
    "        browser.get(url)\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        path = '//*[@class=\"cmp-JobListJobCount-jobCount\"]' \n",
    "        num_jobs = browser.find_element_by_xpath(path).text\n",
    "        num_jobs = re.findall(r'^.+(?= job)', num_jobs)[0]\n",
    "        num_jobs = re.sub(r'\\,| ','', num_jobs)\n",
    "        num_jobs = int(num_jobs)\n",
    "    \n",
    "    except:\n",
    "        print('#',i, company, 'NO JOBS')\n",
    "        \n",
    "        if company not in no_job_on_pages:\n",
    "            no_job_on_pages.append(company)\n",
    "        continue\n",
    "    \n",
    "    page_data = pd.DataFrame({'Company':company,\n",
    "                              'Raw Data':np.nan,\n",
    "                              'Job Title':np.nan,\n",
    "                              'Job Number':num_jobs,\n",
    "                              'Posting Date':np.nan,\n",
    "                              'Job Place':np.nan,}, index = range(num_jobs))\n",
    "    \n",
    "    print('#', i, company, 'num_jobs', num_jobs)\n",
    "    \n",
    "    for i in range(1,101):\n",
    "        try:\n",
    "            # Raw Data\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(i)\n",
    "            raw = browser.find_element_by_xpath(path).text\n",
    "            page_data['Raw Data'].loc[i-1] = raw\n",
    "\n",
    "            # Job Title\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(i)\n",
    "            title = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Title'].loc[i-1] = title\n",
    "\n",
    "            # Date\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(i)\n",
    "            date_post = browser.find_element_by_xpath(path).text\n",
    "            if 'easily' in date_post.lower():\n",
    "                path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(i)\n",
    "                date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "            page_data['Posting Date'].loc[i-1] = date_post\n",
    "\n",
    "            # Place\n",
    "            path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(i)\n",
    "            place = browser.find_element_by_xpath(path).text\n",
    "            page_data['Job Place'].loc[i-1] = place\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if num_jobs>100:\n",
    "        for n in range(1, num_jobs//150+1):\n",
    "            try:\n",
    "                link = url + '?start={}'.format(150*n)\n",
    "                browser.get(link)\n",
    "                sleep(2)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for i in range(1,101):\n",
    "                try:\n",
    "                    \n",
    "                    # Raw Data\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a'.format(i)\n",
    "                    raw = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Raw Data'].loc[n*100+i-1] = raw\n",
    "\n",
    "                    # Job Title\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[1]'.format(i)\n",
    "                    title = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Title'].loc[n*100+i-1] = title\n",
    "\n",
    "                    # Date\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div'.format(i)\n",
    "                    date_post = browser.find_element_by_xpath(path).text\n",
    "                    if 'easily' in date_post.lower():\n",
    "                        path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[3]/div[2]'.format(i)\n",
    "                        date_post = browser.find_element_by_xpath(path).text\n",
    "\n",
    "                    page_data['Posting Date'].loc[n*100+i-1] = date_post\n",
    "\n",
    "                    # Place\n",
    "                    path = '/html/body/div[2]/div/div[1]/main/div/div[2]/div/div/div[2]/div[1]/ul/li[{}]/a/div[1]/div[2]'.format(i)\n",
    "                    place = browser.find_element_by_xpath(path).text\n",
    "                    page_data['Job Place'].loc[n*100+i-1] = place\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    page_data = page_data[((~page_data['Raw Data'].isna())) |\n",
    "                          ((~page_data['Job Title'].isna()) &\n",
    "                          (~page_data['Posting Date'].isna()) &\n",
    "                          (~page_data['Job Place'].isna()))].reset_index(drop=True)\n",
    "\n",
    "    print('Pulled Jobs', page_data.shape[0], '\\n')\n",
    "    \n",
    "    pages_posts = pd.concat([pages_posts, page_data], axis=0, ignore_index=True)\n",
    "    pages_posts['Current Date'] = date.today().strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293, 9)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reional_pages_posts = pd.merge(reional_pages_posts, \n",
    "                               companies_list[['Company Original','Headquarters Country']],\n",
    "                               how='left',\n",
    "                               left_on='Company',\n",
    "                               right_on='Company Original')\n",
    "reional_pages_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "reional_pages_posts['Job Title Regional'] = reional_pages_posts['Job Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "CPU times: user 3.31 s, sys: 193 ms, total: 3.5 s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,j in enumerate(reional_pages_posts[reional_pages_posts['Headquarters Country'].isin(no_english)].index):\n",
    "    traslation = translator.translate(reional_pages_posts['Job Title Regional'].loc[j]).text\n",
    "    reional_pages_posts['Job Title'].loc[j] = traslation\n",
    "    if i%100==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4986,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reional_pages_posts.to_csv('Regional Data-10-08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66668, 11)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([pages_posts, reional_pages_posts]).reset_index(drop=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company                     0\n",
       "Raw Data                    0\n",
       "Job Title                   0\n",
       "Job Number                  0\n",
       "Posting Date             8603\n",
       "Job Place                8603\n",
       "Current Date                0\n",
       "Company Original        65375\n",
       "Headquarters Country    65375\n",
       "Job Title Regional      65375\n",
       "Raw Data Translated     65375\n",
       "dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Indeed-Raw-Data-{}.pkl'.format(date.today().strftime(\"%d-%m-%Y\")), 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 228)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Company'].nunique(), companies_list['Company Original'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in companies_list['Company Original'].unique() if x not in test['Company'].unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting missed data from raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Raw Data'] = test['Raw Data'].str.replace(r'Tagen|päivää|dagen|dag|dagar |jours|dny|Tag', 'days ago ').str.replace(r'Stunde|timmar', 'hours ago ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Job Title Raw'] = test['Raw Data'].str.split('\\n', expand=True)[0]\n",
    "test['Job Place Raw'] = test['Raw Data'].str.split('\\n', expand=True)[2]\n",
    "test['Posting Date Raw'] = test['Raw Data'].str.extract(r'(.+(?= ago))', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Job Title'] = test['Job Title'].fillna(test['Job Title Raw'])\n",
    "test['Job Place'] = test['Job Place'].fillna(test['Job Place Raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Posting Date Processed'] = test['Posting Date'].fillna(test['Posting Date Raw'])\n",
    "test['Posting Date Processed'] = test['Posting Date Processed'].str.replace(r'Tagen|päivää|dagen|dag|dagar |jours|dny|Tag', 'days ago ').str.replace(r'Stunde|timmar', 'hours ago ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.index:\n",
    "\n",
    "    if 'hour' in str(test['Posting Date Processed'].loc[i]):\n",
    "        test['Posting Date Processed'].loc[i] = 1\n",
    "    \n",
    "    if 'minute' in str(test['Posting Date Processed'].loc[i]):\n",
    "        test['Posting Date Processed'].loc[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Posting Date Num'] = test['Posting Date Processed'].astype(str).str.extract(r'(\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Posting Date Raw</th>\n",
       "      <th>Posting Date Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>6 days ago</td>\n",
       "      <td>6 days</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>6 days ago</td>\n",
       "      <td>6 days</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Posting Date Posting Date Raw  Posting Date Num\n",
       "19954    6 days ago           6 days               6.0\n",
       "4703     6 days ago           6 days               6.0\n",
       "10912  30+ days ago         30+ days              30.0"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['Posting Date', 'Posting Date Raw', 'Posting Date Num']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20523, 16)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(~test['Job Place'].isna()) &\n",
    "     (~test['Posting Date Processed'].isna()) & \n",
    "     (~test.duplicated(subset=['Job Title',\n",
    "                              'Company', \n",
    "                              'Posting Date Processed',\n",
    "                              'Job Place'], keep='first'))\n",
    "    ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20523, 16)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(~test['Job Place'].isna()) &\n",
    "            (~test['Posting Date Processed'].isna()) & \n",
    "            (~test.duplicated(subset=['Job Title',\n",
    "                                      'Company', \n",
    "                                      'Posting Date Processed',\n",
    "                                      'Job Place'], keep='first'))].sort_values('Job Title')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missed companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_jobs_list = [x for x in companies_list['Company Original'].unique() if x not in test['Company'].unique()]\n",
    "len(no_jobs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 1)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_jobs_df = pd.DataFrame(no_jobs_list, columns=['Company'])\n",
    "no_jobs_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting correct titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Job Title New'] = test['Job Title'].fillna('-999').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10718"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sales\n",
    "sales_idx = test[(test['Job Title New'].str.lower().str.contains(r'sale'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[sales_idx] = 'sales'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7759"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# engineering\n",
    "eng_idx = test[test['Job Title New'].str.lower().str.contains(r' engineer(?![a-z])|engineer |develop|architect')].index.to_list()\n",
    "test['Job Title New'].loc[eng_idx] = 'engineering'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7117"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# program & product management\n",
    "prod_idx = test[((test['Job Title New'].str.lower().str.contains(r' manager(?![a-z])') |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'manager |team lead')))) &\n",
    "\n",
    "                 ((test['Job Title New'].str.lower().str.contains(r' product(?![a-z])') |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'product ')))) |\n",
    "\n",
    "                 ((test['Job Title New'].str.lower().str.contains(r' program(?![a-z])') |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'program ')))) | \n",
    "                \n",
    "                (test['Job Title New'].str.lower().str.contains(r'product owner|product specialist'))\n",
    "\n",
    "                ]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[prod_idx] = 'program & product management'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6343"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analytics\n",
    "analytics_idx = test[(test['Job Title New'].str.lower().str.contains(r'scientist')) | \n",
    "                     (test['Job Title New'].str.lower().str.contains(r'research')) |\n",
    "                     (test['Job Title New'].str.lower().str.contains(r'analys'))\n",
    "                    ]['Job Title New'].index.to_list()\n",
    "\n",
    "test['Job Title New'].loc[analytics_idx] = 'analytics'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6128"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# design\n",
    "design_idx = test[(test['Job Title New'].str.lower().str.contains(r'design'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[design_idx] = 'design'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5798"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consulting\n",
    "consult_idx = test[(test['Job Title New'].str.lower().str.contains(r'consultant|advis'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[consult_idx] = 'consulting'\n",
    "test['Job Title New'].nunique()\n",
    "#.value_counts()#.nunique()##.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5474"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real estate\n",
    "re_idx = test[(test['Job Title New'].str.lower().str.contains(r'real estate|closer'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[re_idx] = 'real estate'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4366"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# operational\n",
    "oper_idx = test[(test['Job Title New'].str.lower().str.contains(r'support')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'inventory')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'representative|executive assistant')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'office associate')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'fulfillment')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'administr')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'specialist')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'coordinator|buyers assistant')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'operations|supply associate')) \n",
    "                \n",
    "\n",
    "                ]['Job Title New'].index.to_list()\n",
    "\n",
    "test['Job Title New'].loc[oper_idx] = 'operational'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# techicians & general labor\n",
    "general_idx = test[\n",
    "                (test['Job Title New'].str.lower().str.contains(r'operator|technical|mechanic')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'lot attendant|freight\\/receiving|auto body shop')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'warehouse worker|deliver')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'roofer|vehicle condition assessor')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'installer|detailer|electrician|worker')) |\n",
    "\n",
    "                (test['Job Title New'].str.lower().str.contains(r'painter|concierge|driver|cashier|drive with lyft')) |\n",
    "\n",
    "    \n",
    "                (test['Job Title New'].str.lower().str.contains(r'retail store associate|courier')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'warehouse store associate|stock')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'warehouse associate|lot associate')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'supervisor|librarian')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'technici|general labor')) \n",
    "                ]['Job Title New'].index.to_list()\n",
    "\n",
    "test['Job Title New'].loc[general_idx] = 'technicians & general labor'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general management\n",
    "mng_idx = test[((test['Job Title New'].str.lower().str.contains(r' manager(?![a-z])') |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'manager |manager\\,|lead')))) &\n",
    "               \n",
    "               \n",
    "\n",
    "                 (~test['Job Title New'].fillna('-999').astype(str).str.lower().str.contains(r' product(?![a-z])') &\n",
    "                 (~test['Job Title New'].fillna('-999').astype(str).str.lower().str.contains(r'product '))) &\n",
    "\n",
    "\n",
    "                 (~test['Job Title New'].fillna('-999').astype(str).str.lower().str.contains(r' program(?![a-z])') &\n",
    "                 (~test['Job Title New'].fillna('-999').astype(str).str.lower().str.contains(r'program ')))]['Job Title New'].index.to_list()\n",
    "\n",
    "test['Job Title New'].loc[mng_idx] = 'general management'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# executives\n",
    "exec_idx = test[(test['Job Title New'].str.lower().str.contains(r'director')) | \n",
    "                (test['Job Title New'].str.lower().str.contains(r'head of')) |\n",
    "                (test['Job Title New'].str.lower().str.contains(r'partner')) | \n",
    "                 (test['Job Title New'].str.lower().str.contains(r'president')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'officer')) |\n",
    "                (test['Job Title New'].str.contains(r'VP')) |\n",
    "                 (test['Job Title New'].str.lower().str.contains(r'executiv')) \n",
    "                \n",
    "                \n",
    "                ]['Job Title New'].index.to_list()\n",
    "\n",
    "test['Job Title New'].loc[exec_idx] = 'top/middle-level management'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HR\n",
    "hr_idx = test[(test['Job Title New'].str.lower().str.contains(r'hr|human resou|hiring|recruit|talent|trainer'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[hr_idx] = 'human resources'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marketing\n",
    "marketing_idx = test[(test['Job Title New'].str.lower().str.contains(r'marketing|copywriter|marketer|content|merchandising'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[marketing_idx] = 'marketing'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finance\n",
    "finance_idx = test[(test['Job Title New'].str.lower().str.contains(r'accountant|financ|payroll|mortgage|risk|tax'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[finance_idx] = 'finance'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Legal\n",
    "legal_idx = test[(test['Job Title New'].str.lower().str.contains(r'legal|counsel'))]['Job Title New'].index.to_list()\n",
    "test['Job Title New'].loc[legal_idx] = 'legal'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['Job Title New'] !='-999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engineering                     4378\n",
       "technicians & general labor     4263\n",
       "general management              2064\n",
       "operational                     1939\n",
       "sales                           1592\n",
       "other                           1233\n",
       "top/middle-level management     1082\n",
       "analytics                       1063\n",
       "program & product management     877\n",
       "consulting                       513\n",
       "finance                          496\n",
       "design                           373\n",
       "real estate                      337\n",
       "legal                            124\n",
       "human resources                  113\n",
       "marketing                         76\n",
       "Name: Job Title New, dtype: int64"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Job Title New'].value_counts().head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940204180845892"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_titles = test['Job Title New'].value_counts().head(15).index.to_list()\n",
    "test[test['Job Title New'].isin(main_titles)].shape[0]/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other Titles\n",
    "other_idx = test[~test['Job Title New'].isin(main_titles)].index.to_list()\n",
    "test['Job Title New'].loc[other_idx] = 'other'\n",
    "test['Job Title New'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engineering                     4378\n",
       "technicians & general labor     4263\n",
       "general management              2064\n",
       "operational                     1939\n",
       "sales                           1592\n",
       "other                           1233\n",
       "top/middle-level management     1082\n",
       "analytics                       1063\n",
       "program & product management     877\n",
       "consulting                       513\n",
       "finance                          496\n",
       "design                           373\n",
       "real estate                      337\n",
       "legal                            124\n",
       "human resources                  113\n",
       "marketing                         76\n",
       "Name: Job Title New, dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Job Title New'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting weekly stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_key = '1VvDfqliy3PB-X7Ro9PNYL-hHbOLJ4P4FeMNcrz5w624'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "scope = ['https://spreadsheets.google.com/feeds'] \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/macbook/Downloads/gs-credentials.json', scope) \n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, no_jobs_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First two weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7379, 17)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['Posting Date Num']<=15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1031, 3)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupe_df = test[test['Posting Date Num']<=15].groupby(['Company','Job Title New'])['Job Title'].count()\n",
    "groupe_df = groupe_df.reset_index()\n",
    "groupe_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 17)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_two =pd.pivot_table(groupe_df, values='Job Title', index=['Company'],\n",
    "                        columns=['Job Title New'], aggfunc=np.sum).reset_index()\n",
    "pivot_df_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_two['Total'] = pivot_df_two.loc[:,'analytics':'top/middle-level management'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_two['Company'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missed comps in pivot\n",
    "missed_in_pivot = [x for x in test['Company'].unique() if x not in pivot_df_two['Company'].unique()]\n",
    "missed_in_pivot_df_two = pd.DataFrame(missed_in_pivot, columns=['Company'])\n",
    "len(missed_in_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_two = pd.concat([pivot_df_two, missed_in_pivot_df_two], ignore_index=True)\n",
    "pivot_df_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_two = pivot_df_two.sort_values('Company').rename(columns={'Company':'Company'})\n",
    "pivot_df_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cols = ['Company', 'Total','analytics', 'consulting', 'design', 'engineering',\n",
    "           'finance', 'general management', 'human resources', 'legal',\n",
    "           'marketing', 'operational', 'other', 'program & product management',\n",
    "           'real estate', 'sales', 'technicians & general labor',\n",
    "           'top/middle-level management']\n",
    "pivot_df_two = pivot_df_two[gs_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet '0 to 15 days back. 26-08-2020' id:333493564>"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2g.upload(pivot_df_two.fillna('-'),\n",
    "           spreadsheet_key,\n",
    "           '0 to 15 days back. {}'.format(date.today().strftime(\"%d-%m-%Y\")),\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second two weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13178, 17)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['Posting Date Num']>=15) & (test['Posting Date Num']<=30)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406, 3)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupe_df = test[(test['Posting Date Num']>=15) & (test['Posting Date Num']<=30)].groupby(['Company','Job Title New'])['Job Title'].count()\n",
    "groupe_df = groupe_df.reset_index()\n",
    "groupe_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 17)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_four =pd.pivot_table(groupe_df, values='Job Title', index=['Company'],\n",
    "                        columns=['Job Title New'], aggfunc=np.sum).reset_index()\n",
    "pivot_df_four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_four['Company'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_four['Total'] = pivot_df_four.loc[:,'analytics':'top/middle-level management'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missed comps in pivot\n",
    "missed_in_pivot = [x for x in test['Company'].unique() if x not in pivot_df_four['Company'].unique()]\n",
    "missed_in_pivot_df_four = pd.DataFrame(missed_in_pivot, columns=['Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_four = pd.concat([pivot_df_four, missed_in_pivot_df_four], ignore_index=True)\n",
    "pivot_df_four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_four = pivot_df_four.sort_values('Company').rename(columns={'Company':'Company'})\n",
    "pivot_df_four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_four = pivot_df_four[gs_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet '15 to 30 days back. 26-08-2020' id:275133337>"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2g.upload(pivot_df_four.fillna('-'),\n",
    "           spreadsheet_key,\n",
    "           '15 to 30 days back. {}'.format(date.today().strftime(\"%d-%m-%Y\")),\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More than month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9315, 17)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['Posting Date Num']>=30)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241, 3)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupe_df = test[test['Posting Date Num']>=30].groupby(['Company','Job Title New'])['Job Title'].count()\n",
    "groupe_df = groupe_df.reset_index()\n",
    "groupe_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 17)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_month = pd.pivot_table(groupe_df, values='Job Title', index=['Company'],\n",
    "                        columns=['Job Title New'], aggfunc=np.sum).reset_index()\n",
    "pivot_df_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_month['Company'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_month['Total'] = pivot_df_month.loc[:,'analytics':'top/middle-level management'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missed comps in pivot\n",
    "missed_in_pivot = [x for x in test['Company'].unique() if x not in pivot_df_month['Company'].unique()]\n",
    "missed_in_pivot_df_month = pd.DataFrame(missed_in_pivot, columns=['Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_month = pd.concat([pivot_df_month, missed_in_pivot_df_month], ignore_index=True)\n",
    "pivot_df_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 18)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df_month = pivot_df_month.sort_values('Company').rename(columns={'Company':'Company'})\n",
    "pivot_df_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_month = pivot_df_month[gs_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet '30+ days back. 26-08-2020' id:91773279>"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2g.upload(pivot_df_month.fillna('-'),\n",
    "           spreadsheet_key,\n",
    "           '30+ days back. {}'.format(date.today().strftime(\"%d-%m-%Y\")),\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet 'Raw Data. 26-08-2020' id:529097850>"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2g.upload(test[['Company','Job Title','Posting Date','Job Title New','Job Place']].fillna('-'),\n",
    "           spreadsheet_key,\n",
    "           'Raw Data. {}'.format(date.today().strftime(\"%d-%m-%Y\")),\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
